{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "\n",
    "def load_data(filepath, delimiter=\",\", dtype=float):\n",
    "    \"\"\"Load a numerical numpy array from a file.\"\"\"\n",
    "\n",
    "    print(f\"Loading {filepath}...\")\n",
    "    with open(filepath, \"r\") as f:\n",
    "        data_iterator = csv.reader(f, delimiter=delimiter)\n",
    "        data_list = list(data_iterator)\n",
    "    data = np.asarray(data_list, dtype=dtype)\n",
    "    print(\"Done.\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading ./mnistdata/mnist_train.csv...\n",
      "Done.\n",
      "Loading ./mnistdata/mnist_test.csv...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "TRAIN_FILE = \"./mnistdata/mnist_train.csv\"\n",
    "TEST_FILE = \"./mnistdata/mnist_test.csv\"\n",
    "\n",
    "train_data = load_data(TRAIN_FILE, ',', int)\n",
    "test_data = load_data(TEST_FILE, ',', int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            \n",
      "      ######                \n",
      "      ################      \n",
      "      ################      \n",
      "           ###########      \n",
      "                  ####      \n",
      "                 ####       \n",
      "                 ####       \n",
      "                ####        \n",
      "                ####        \n",
      "               ####         \n",
      "               ###          \n",
      "              ####          \n",
      "             ####           \n",
      "            #####           \n",
      "            ####            \n",
      "           #####            \n",
      "           ####             \n",
      "          #####             \n",
      "          #####             \n",
      "          ####              \n"
     ]
    }
   ],
   "source": [
    "for row in range(28):\n",
    "    if not sum(test_data[0, 28 * row: 28 * (row + 1)]):\n",
    "        continue\n",
    "    for col in range(28):\n",
    "        idx = row * 28 + col\n",
    "        print(\"#\" if data[0, 1+idx] else \" \", end=\"\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import source files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn import NeuralNet, Layer, LeakyRelu, MSE, Sigmoid, Softmax, CrossEntropyLoss, BinaryCrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_col(x):\n",
    "    return x.reshape((x.size, 1))\n",
    "\n",
    "def test(net, test_data):\n",
    "    correct = 0\n",
    "    for i, test_row in enumerate(test_data):\n",
    "        if not i%1000:\n",
    "            print(i)\n",
    "\n",
    "        t = test_row[0]\n",
    "        x = to_col(test_row[1:])\n",
    "        out = net.forward(x)\n",
    "        guess = np.argmax(out)\n",
    "        if t == guess:\n",
    "            correct += 1\n",
    "\n",
    "    return correct/test_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "Accuracy is 10.10%\n"
     ]
    }
   ],
   "source": [
    "# test_data = load_data(TEST_FILE, \",\", int)\n",
    "\n",
    "accuracy = test(net, test_data)\n",
    "print(f\"Accuracy is {100*accuracy:.2f}%\")     # Expected to be around 10%"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_data):\n",
    "    # Precompute all target vectors.\n",
    "    ts = {}\n",
    "    for t in range(10):\n",
    "        tv = np.zeros((10, 1))\n",
    "        tv[t] = 1\n",
    "        ts[t] = tv\n",
    "\n",
    "    for i, train_row in enumerate(train_data):\n",
    "        if not i%1000:\n",
    "            print(i)\n",
    "\n",
    "        t = ts[train_row[0]]\n",
    "        x = to_col(train_row[1:])\n",
    "        net.train(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_data):\n",
    "    # We no longer need to compute the dictionary `ts`.\n",
    "    for i, train_row in enumerate(train_data):\n",
    "        # if not i%1000:\n",
    "        #     print(i)\n",
    "        t = train_row[0]            # <-- was   t = ts[train_row[0]]\n",
    "        x = to_col(train_row[1:])\n",
    "        net.train(x, t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First configuration we tried.\n",
    "layers = [\n",
    "    Layer(784, 16, LeakyRelu()),\n",
    "    Layer(16, 16, LeakyRelu()),\n",
    "    Layer(16, 10, LeakyRelu()),\n",
    "]\n",
    "net = NeuralNet(layers, MSE(), 0.001)\n",
    "\n",
    "train(net, train_data)\n",
    "\n",
    "accuracy = test(net, test_data)\n",
    "print(f\"Accuracy is {100*accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from, to: 784 16\n",
      "from, to: 16 16\n",
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n",
      "5000\n",
      "6000\n",
      "7000\n",
      "8000\n",
      "9000\n",
      "Accuracy is 11.16%\n"
     ]
    }
   ],
   "source": [
    "# Use a Sigmoid as the final layer\n",
    "layers = [\n",
    "    Layer(784, 16, LeakyRelu()),\n",
    "    Layer(16, 16, LeakyRelu()),\n",
    "    Layer(16, 10, Sigmoid()),\n",
    "]\n",
    "net = NeuralNet(layers, MSE(), 0.001)\n",
    "\n",
    "train(net, train_data)\n",
    "\n",
    "accuracy = test(net, test_data)\n",
    "print(f\"Accuracy is {100*accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BinaryCrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use BinaryCrossEntropyLoss\n",
    "layers = [\n",
    "    Layer(784, 16, LeakyRelu()),\n",
    "    Layer(16, 16, LeakyRelu()),\n",
    "    Layer(16, 10, LeakyRelu()),\n",
    "]\n",
    "net = NeuralNet(layers, BinaryCrossEntropyLoss(), 0.001)\n",
    "\n",
    "train(net, train_data)\n",
    "\n",
    "accuracy = test(net, test_data)\n",
    "print(f\"Accuracy is {100*accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sigmoid at the end and BinaryCrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from, to: 784 16\n",
      "from, to: 16 16\n"
     ]
    }
   ],
   "source": [
    "# sigmoid at the end and the CrossEntropyLoss\n",
    "layers = [\n",
    "    Layer(784, 16, LeakyRelu()),\n",
    "    Layer(16, 16, LeakyRelu()),\n",
    "    Layer(16, 10, Sigmoid()),\n",
    "]\n",
    "net = NeuralNet(layers, BinaryCrossEntropyLoss(), 0.001)\n",
    "\n",
    "train(net, train_data)\n",
    "\n",
    "accuracy = test(net, test_data)\n",
    "print(f\"Accuracy is {100*accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net, train_data):\n",
    "    for i, train_row in enumerate(train_data):\n",
    "        t = train_row[0]  # Assume the first element is the class label\n",
    "        x = to_col(train_row[1:])  # Assume the rest are input features\n",
    "        \n",
    "        # Convert the class label to one-hot encoding\n",
    "        t_one_hot = np.zeros((10, 1))  # net.output_size is the number of classes\n",
    "        t_one_hot[t] = 1\n",
    "\n",
    "        # Train the network\n",
    "        # print(\"x in train:\", x.shape)\n",
    "        net.train(x, t_one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from, to: 784 16\n",
      "from, to: 16 16\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (10,10) and (1,16) not aligned: 10 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 9\u001b[0m\n\u001b[1;32m      2\u001b[0m layers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      3\u001b[0m     Layer(\u001b[38;5;241m784\u001b[39m, \u001b[38;5;241m16\u001b[39m, LeakyRelu()),\n\u001b[1;32m      4\u001b[0m     Layer(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m16\u001b[39m, LeakyRelu()),\n\u001b[1;32m      5\u001b[0m     Layer(\u001b[38;5;241m16\u001b[39m, \u001b[38;5;241m10\u001b[39m, Softmax()),\n\u001b[1;32m      6\u001b[0m ]\n\u001b[1;32m      7\u001b[0m net \u001b[38;5;241m=\u001b[39m NeuralNet(layers, CrossEntropyLoss(), \u001b[38;5;241m0.001\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m test(net, test_data)\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAccuracy is \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m100\u001b[39m\u001b[38;5;241m*\u001b[39maccuracy\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.2f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[2], line 8\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(net, train_data)\u001b[0m\n\u001b[1;32m      6\u001b[0m t \u001b[38;5;241m=\u001b[39m train_row[\u001b[38;5;241m0\u001b[39m]            \u001b[38;5;66;03m# <-- was   t = ts[train_row[0]]\u001b[39;00m\n\u001b[1;32m      7\u001b[0m x \u001b[38;5;241m=\u001b[39m to_col(train_row[\u001b[38;5;241m1\u001b[39m:])\n\u001b[0;32m----> 8\u001b[0m \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/data_science/nn.py:59\u001b[0m, in \u001b[0;36mNeuralNet.train\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     57\u001b[0m db \u001b[38;5;241m=\u001b[39m layer\u001b[38;5;241m.\u001b[39mact_function\u001b[38;5;241m.\u001b[39mdf(y) \u001b[38;5;241m*\u001b[39m dx\n\u001b[1;32m     58\u001b[0m dx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdot(layer\u001b[38;5;241m.\u001b[39m_W\u001b[38;5;241m.\u001b[39mT, db)\n\u001b[0;32m---> 59\u001b[0m dW \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;66;03m# Update parameters\u001b[39;00m\n\u001b[1;32m     62\u001b[0m layer\u001b[38;5;241m.\u001b[39m_W \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlr \u001b[38;5;241m*\u001b[39m dW\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (10,10) and (1,16) not aligned: 10 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "# softmax at the end and the CrossEntropyLoss\n",
    "layers = [\n",
    "    Layer(784, 16, LeakyRelu()),\n",
    "    Layer(16, 16, LeakyRelu()),\n",
    "    Layer(16, 10, Softmax()),\n",
    "]\n",
    "net = NeuralNet(layers, CrossEntropyLoss(), 0.001)\n",
    "\n",
    "train(net, train_data)\n",
    "\n",
    "accuracy = test(net, test_data)\n",
    "print(f\"Accuracy is {100*accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "42AI-cjung-mo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
